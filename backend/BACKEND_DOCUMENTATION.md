# Техническая Документация Бэкенда "ProDvor"

Этот документ служит центральным источником информации для разработки, развертывания и поддержки серверной части платформы "ProDvor".

## 1. Обзор архитектуры

Мы используем микросервисную архитектуру для обеспечения гибкости, масштабируемости и независимого развертывания компонентов.

-   **API Gateway (Kong)**: Единая точка входа для всех клиентских запросов. Отвечает за маршрутизацию, аутентификацию (проверка JWT), ограничение скорости и логирование.
-   **Identity Provider (Keycloak)**: Централизованное управление пользователями, ролями, аутентификацией и авторизацией.
-   **Основные сервисы (Node.js)**: Набор микросервисов, отвечающих за конкретную бизнес-логику:
    -   **`user-service`**: Управление профилями пользователей, настройками, друзьями.
    -   **`team-service`**: Создание команд, управление составом, заявки на вступление.
    -   **`tournament-service`**: Управление турнирами, генерация сеток, обработка результатов.
    -   **`match-service`**: Логика матчей, статистика, разрешение споров.
    -   **`chat-service`**: Обработка real-time сообщений через WebSocket, управление комнатами чатов, история сообщений. Для обеспечения надежной доставки и масштабируемости использует брокер сообщений.
    -   **`notification-service`**: Отправка асинхронных уведомлений (push, email).
-   **Брокер сообщений (Kafka & RabbitMQ)**: Асинхронное взаимодействие между сервисами. Используется для доставки сообщений в `chat-service`, обработки оффлайн-сообщений и для `notification-service`.
-   **База данных (PostgreSQL)**: Основное хранилище данных для всех сервисов.
-   **AI Gateway (Genkit)**: Отдельный шлюз или сервис, который инкапсулирует взаимодействие с моделями Google AI, предоставляя безопасные эндпоинты для фронтенда.

## 2. Технологический стек

| Компонент            | Технология                    | Примечание                                                          |
| :---                 | :---                          | :---                                                                |
| **Среда выполнения** | Node.js (v20+)                | Используем LTS-версию для стабильности.                             |
| **Фреймворк**        | NestJS                        | Предоставляет модульную архитектуру и DI "из коробки".              |
| **База данных**      | PostgreSQL (v15+)             | Надежная и масштабируемая реляционная СУБД.                         |
| **ORM**              | Prisma                        | Упрощает взаимодействие с базой данных и миграции.                  |
| **API Gateway**      | Kong                          | Централизованная обработка входящих запросов.                       |
| **GUI для Kong**     | Konga                         | Веб-интерфейс для удобной настройки Kong.                           |
| **IdP**              | Keycloak                      | Управление пользователями, ролями и аутентификацией.                |
| **Брокер сообщений** | Apache Kafka & RabbitMQ       | Для асинхронных операций, стриминга и сверхвысоких нагрузок.         |
| **Контейнеризация**  | Docker, Docker Compose        | Для локальной разработки и развертывания.                           |
| **Кеширование**      | Redis                         | Для кеширования сессий, часто запрашиваемых данных.                 |

### Выбор брокера: Kafka как основа для масштабирования

С учетом долгосрочных целей — поддержка **трансляций, стримов и аудитории в 80 миллионов пользователей** — выбор однозначно падает на **Apache Kafka**.

Изначально для прототипа мог бы подойти более легковесный брокер вроде NATS или RabbitMQ, но для заявленных масштабов они не обладают необходимой пропускной способностью и возможностями обработки потоков.

**Почему Kafka — это правильный выбор для ProDvor:**

| Критерий                     | Kafka                                                                                       | Другие брокеры (NATS/RabbitMQ)                                             | Обоснование для ProDvor                                                                                                               |
| :---                         | :---                                                                                        | :---                                                                       | :---                                                                                                                                  |
| **Масштабируемость и Throughput** | Спроектирован для **триллионов сообщений в день**. Горизонтально масштабируется до огромных кластеров. | Оптимизированы для low-latency, но уступают в чистой пропускной способности. | **80 млн пользователей** будут генерировать колоссальный объем событий (чаты, действия, статистика). Kafka справится с этой нагрузкой.     |
| **Обработка потоков (Streaming)** | Нативная поддержка стриминга и обработки потоков данных (Kafka Streams, ksqlDB).          | В основном используются для простой доставки сообщений (point-to-point, pub/sub). | Это **ключевое требование** для будущих трансляций и стримов. Мы сможем в реальном времени обрабатывать видеопотоки, статистику и т.д. |
| **Надежность и персистентность**  | Данные хранятся в **распределенном, отказоустойчивом логе**. Возможен повторный просмотр событий. | Персистентность есть, но не является ядром архитектуры, как у Kafka.      | Мы не можем позволить себе терять сообщения чатов или события матчей. Прочный лог Kafka гарантирует сохранность данных.             |
| **Экосистема и комьюнити**      | Огромная экосистема коннекторов (базы данных, хранилища) и мощное комьюнити. Промышленный стандарт. | Экосистемы меньше и более нишевые.                                          | Мы сможем легко интегрировать аналитические системы, data lake и другие сервисы в будущем.                                           |

**Вывод:** Несмотря на более высокий порог входа, **Kafka является стратегически верным выбором**. Он закладывает фундамент для платформы, способной выдержать сверхвысокие нагрузки и реализовать сложный функционал, такой как real-time стриминг и аналитика.

### Модель "Правильный инструмент для правильной задачи": Kafka + RabbitMQ

В сложных микросервисных системах абсолютно нормально и даже часто правильно использовать несколько брокеров сообщений, выбирая лучший инструмент для каждой конкретной задачи.

| Задача                                     | Рекомендуемый брокер | Почему?                                                                                                       |
| :----------------------------------------- | :------------------- | :------------------------------------------------------------------------------------------------------------ |
| **Сообщения в чате**                       | **Kafka**            | Нужна высокая пропускная способность, гарантированный порядок и возможность хранить историю для новых участников. |
| **Уведомления (push, email)**              | **RabbitMQ**         | Идеально для очередей задач. Можно легко маршрутизировать задания разным "воркерам" (email-sender, push-sender). |
| **Статистика матчей в реальном времени**   | **Kafka**            | Это классический поток событий (event stream), который можно будет анализировать в реальном времени.         |
| **Видео-трансляции (будущая фича)**        | **Kafka**            | Это основная причина выбора Kafka. Он создан для обработки потоков данных такого масштаба.                    |
| **Фоновые задачи (генерация отчета и т.д.)** | **RabbitMQ**         | Отличный выбор для отложенных задач, которые не требуют строгой последовательности событий.                   |

**Архитектурное решение для ProDvor:** Для обеспечения максимальной эффективности и использования правильного инструмента для каждой задачи, наша архитектура **с самого начала включает и Kafka, и RabbitMQ**.

-   **Kafka** служит основой для высоконагруженных потоков данных: чаты, статистика в реальном времени, и будущие видео-трансляции.
-   **RabbitMQ** используется как классический брокер для асинхронных задач, таких как отправка уведомлений (email, push), обработка фоновых заданий и других сценариев, где важна гибкая маршрутизация.

Такой подход "polyglot messaging" позволяет нам строить более надежную и специализированную систему, готовую к любым нагрузкам.

## 3. Настройка окружения

### Пример `docker-compose.yml`

```yaml
version: '3.8'

services:
  postgres:
    image: postgres:15
    restart: always
    environment:
      POSTGRES_USER: prodvor_user
      POSTGRES_PASSWORD: very_strong_password
      POSTGRES_DB: prodvor_db
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  keycloak:
    image: quay.io/keycloak/keycloak:22.0.1
    command: start-dev
    environment:
      KEYCLOAK_ADMIN: admin
      KEYCLOAK_ADMIN_PASSWORD: admin
    ports:
      - "8180:8080"

  app-service:
    build: .
    restart: always
    ports:
      - "3000:3000"
    depends_on:
      - postgres
      - keycloak

volumes:
  postgres_data:
```

## 4. Спецификация API (Пример для `user-service`)

Все API должны следовать спецификации OpenAPI 3.0.

```yaml
openapi: 3.0.0
info:
  title: User Service API
  version: 1.0.0
paths:
  /users/{userId}:
    get:
      summary: Get user by ID
      parameters:
        - name: userId
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: A user object
          content:
            application/json:
              schema:
                '$ref': '#/components/schemas/User'
components:
  schemas:
    User:
      type: object
      properties:
        id:
          type: string
        name:
          type: string
        email:
          type: string
        role:
          type: string
```

## 5. Аутентификация и авторизация (детально)

Процесс описан в [AUTH_IMPLEMENTATION.md](AUTH_IMPLEMENTATION.md).

Ключевые моменты для бэкенда:
1.  **Защита API**: Все эндпоинты, кроме публичных (`/register`, `/login`, `/health`), должны быть защищены в Kong с помощью `openid-connect` плагина.
2.  **Информация о пользователе**: Kong, после валидации JWT, передает информацию о пользователе (claims) в заголовках (`X-Userinfo`, `X-Authenticated-Userid`). Сервисы должны доверять этим заголовкам.
3.  **Регистрация**: Эндпоинт `/register` должен быть публичным. Он принимает данные пользователя, валидирует их и использует **Keycloak Admin API** для создания нового пользователя. Для этого необходим сервисный аккаунт с правами `manage-users`.
4.  **Роли**: Сервисы должны проверять роль пользователя (переданную в JWT) для выполнения авторизованных действий.

## 6. Взаимодействие с AI-сервисами (Genkit)

Для обеспечения безопасности и контроля, Genkit-флоу не должны вызываться напрямую с фронтенда в продакшене.

1.  **Backend-for-Frontend (BFF)**: Создайте специальный сервис или эндпоинты в существующих сервисах, которые будут выступать в роли прокси для Genkit.
2.  **Аутентификация**: Эти прокси-эндпоинты должны быть защищены JWT, как и остальные части API.
3.  **Передача данных**: BFF-эндпоинт принимает запрос от фронтенда, обогащает его необходимой информацией из базы данных (например, полная статистика игрока) и затем вызывает соответствующий Genkit-флоу.
4.  **Безопасность ключей**: `GOOGLE_API_KEY` должен храниться только на бэкенде и никогда не передаваться на клиент.
