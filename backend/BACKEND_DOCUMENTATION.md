# Техническая Документация Бэкенда "ProDvor"

Этот документ служит центральным источником информации для разработки, развертывания и поддержки серверной части платформы "ProDvor".

## 1. Обзор архитектуры

Мы используем микросервисную архитектуру для обеспечения гибкости, масштабируемости и независимого развертывания компонентов.

-   **API Gateway (Kong)**: Единая точка входа для всех клиентских запросов. Отвечает за маршрутизацию, аутентификацию (проверка JWT), ограничение скорости и логирование.
-   **Identity Provider (Keycloak)**: Централизованное управление пользователями, ролями, аутентификацией и авторизацией.
-   **Основные сервисы (Node.js)**: Набор микросервисов, отвечающих за конкретную бизнес-логику:
    -   **`user-service`**: Управление профилями пользователей, настройками, друзьями.
    -   **`team-service`**: Создание команд, управление составом, заявки на вступление.
    -   **`tournament-service`**: Управление турнирами, генерация сеток, обработка результатов.
    -   **`match-service`**: Логика матчей, статистика, разрешение споров.
    -   **`chat-service`**: Обработка real-time сообщений через WebSocket, управление комнатами чатов, история сообщений. Для обеспечения надежной доставки и масштабируемости использует брокер сообщений.
    -   **`notification-service`**: Отправка асинхронных уведомлений (push, email).
-   **Брокер сообщений (Kafka)**: Асинхронное взаимодействие между сервисами. Используется для доставки сообщений в `chat-service`, обработки оффлайн-сообщений и для `notification-service`.
-   **База данных (PostgreSQL)**: Основное хранилище данных для всех сервисов.
-   **AI Gateway (Genkit)**: Отдельный шлюз или сервис, который инкапсулирует взаимодействие с моделями Google AI, предоставляя безопасные эндпоинты для фронтенда.

## 2. Технологический стек

| Компонент            | Технология                    | Примечание                                                          |
| :---                 | :---                          | :---                                                                |
| **Среда выполнения** | Node.js (v20+)                | Используем LTS-версию для стабильности.                             |
| **Фреймворк**        | NestJS                        | Предоставляет модульную архитектуру и DI "из коробки".              |
| **База данных**      | PostgreSQL (v15+)             | Надежная и масштабируемая реляционная СУБД.                         |
| **ORM**              | Prisma                        | Упрощает взаимодействие с базой данных и миграции.                  |
| **API Gateway**      | Kong                          | Централизованная обработка входящих запросов.                       |
| **GUI для Kong**     | Konga                         | Веб-интерфейс для удобной настройки Kong.                           |
| **IdP**              | Keycloak                      | Управление пользователями, ролями и аутентификацией.                |
| **Брокер сообщений** | Apache Kafka                  | Для асинхронных операций, стриминга и сверхвысоких нагрузок.         |
| **Контейнеризация**  | Docker, Docker Compose        | Для локальной разработки и развертывания.                           |
| **Кеширование**      | Redis                         | Для кеширования сессий, часто запрашиваемых данных.                 |

### Выбор брокера: Kafka как основа для масштабирования

С учетом долгосрочных целей — поддержка **трансляций, стримов и аудитории в 80 миллионов пользователей** — выбор однозначно падает на **Apache Kafka**.

Изначально для прототипа мог бы подойти более легковесный брокер вроде NATS или RabbitMQ, но для заявленных масштабов они не обладают необходимой пропускной способностью и возможностями обработки потоков.

**Почему Kafka — это правильный выбор для ProDvor:**

| Критерий                     | Kafka                                                                                       | Другие брокеры (NATS/RabbitMQ)                                             | Обоснование для ProDvor                                                                                                               |
| :---                         | :---                                                                                        | :---                                                                       | :---                                                                                                                                  |
| **Масштабируемость и Throughput** | Спроектирован для **триллионов сообщений в день**. Горизонтально масштабируется до огромных кластеров. | Оптимизированы для low-latency, но уступают в чистой пропускной способности. | **80 млн пользователей** будут генерировать колоссальный объем событий (чаты, действия, статистика). Kafka справится с этой нагрузкой.     |
| **Обработка потоков (Streaming)** | Нативная поддержка стриминга и обработки потоков данных (Kafka Streams, ksqlDB).          | В основном используются для простой доставки сообщений (point-to-point, pub/sub). | Это **ключевое требование** для будущих трансляций и стримов. Мы сможем в реальном времени обрабатывать видеопотоки, статистику и т.д. |
| **Надежность и персистентность**  | Данные хранятся в **распределенном, отказоустойчивом логе**. Возможен повторный просмотр событий. | Персистентность есть, но не является ядром архитектуры, как у Kafka.      | Мы не можем позволить себе терять сообщения чатов или события матчей. Прочный лог Kafka гарантирует сохранность данных.             |
| **Экосистема и комьюнити**      | Огромная экосистема коннекторов (базы данных, хранилища) и мощное комьюнити. Промышленный стандарт. | Экосистемы меньше и более нишевые.                                          | Мы сможем легко интегрировать аналитические системы, data lake и другие сервисы в будущем.                                           |

**Вывод:** Несмотря на более высокий порог входа, **Kafka является стратегически верным выбором**. Он закладывает фундамент для платформы, способной выдержать сверхвысокие нагрузки и реализовать сложный функционал, такой как real-time стриминг и аналитика.

## 3. Настройка окружения

### Пример `docker-compose.yml`

```yaml
version: '3.8'

services:
  postgres:
    image: postgres:15
    restart: always
    environment:
      POSTGRES_USER: prodvor_user
      POSTGRES_PASSWORD: very_strong_password
      POSTGRES_DB: prodvor_db
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  keycloak:
    image: quay.io/keycloak/keycloak:22.0.1
    command: start-dev
    environment:
      KEYCLOAK_ADMIN: admin
      KEYCLOAK_ADMIN_PASSWORD: admin
    ports:
      - "8180:8080"

  app-service:
    build: .
    restart: always
    ports:
      - "3000:3000"
    depends_on:
      - postgres
      - keycloak

volumes:
  postgres_data:
```

## 4. Спецификация API (Пример для `user-service`)

Все API должны следовать спецификации OpenAPI 3.0.

```yaml
openapi: 3.0.0
info:
  title: User Service API
  version: 1.0.0
paths:
  /users/{userId}:
    get:
      summary: Get user by ID
      parameters:
        - name: userId
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: A user object
          content:
            application/json:
              schema:
                '$ref': '#/components/schemas/User'
components:
  schemas:
    User:
      type: object
      properties:
        id:
          type: string
        name:
          type: string
        email:
          type: string
        role:
          type: string
```

## 5. Аутентификация и авторизация (детально)

Процесс описан в [AUTH_IMPLEMENTATION.md](AUTH_IMPLEMENTATION.md).

Ключевые моменты для бэкенда:
1.  **Защита API**: Все эндпоинты, кроме публичных (`/register`, `/login`, `/health`), должны быть защищены в Kong с помощью `openid-connect` плагина.
2.  **Информация о пользователе**: Kong, после валидации JWT, передает информацию о пользователе (claims) в заголовках (`X-Userinfo`, `X-Authenticated-Userid`). Сервисы должны доверять этим заголовкам.
3.  **Регистрация**: Эндпоинт `/register` должен быть публичным. Он принимает данные пользователя, валидирует их и использует **Keycloak Admin API** для создания нового пользователя. Для этого необходим сервисный аккаунт с правами `manage-users`.
4.  **Роли**: Сервисы должны проверять роль пользователя (переданную в JWT) для выполнения авторизованных действий.

### 5.1. Отключение локальной JWT-проверки для продакшена

**Важно:** Когда приложение разворачивается за API-шлюзом (Kong), который сам проверяет токен, глобальный `JwtAuthGuard` на бэкенде становится не нужен и должен быть отключен. Это предотвращает двойную проверку и возможные ошибки.

По умолчанию этот гард **уже отключен** для подготовки к продакшен-среде. Это сделано путем комментирования провайдера `APP_GUARD` в файле `src/app.module.ts`:

```typescript
// src/app.module.ts

@Module({
  imports: [/* ... */],
  controllers: [AppController],
  providers: [
    AppService,
    // { // <-- ЭТА СЕКЦИЯ ОТКЛЮЧЕНА
    //   provide: APP_GUARD,
    //   useClass: JwtAuthGuard,
    // }, // <-- ЭТА СЕКЦИЯ ОТКЛЮЧЕНА
  ],
})
export class AppModule {}
```

Если вам нужно включить локальную проверку JWT для разработки без Kong, просто раскомментируйте этот блок.

### 5.2. Безопасность API Gateway (Kong)

В продакшен-среде безопасность API-шлюза является критически важной. Вот ключевые шаги, которые необходимо предпринять:

1.  **Защита Admin API**:
    *   Admin API Kong (по умолчанию на порту `:8001`) **никогда не должен быть доступен из публичной сети**. Он должен быть либо полностью закрыт файрволом и доступен только из внутренней сети, либо защищен с помощью аутентификации (например, через плагин `key-auth` или `jwt`).
    *   В нашем `docker-compose.yml` он доступен для удобства локальной настройки через Konga.

2.  **Шифрование трафика (SSL/TLS)**:
    *   Весь трафик между клиентом и Kong должен быть зашифрован.
    *   **Действие**: Вам необходимо получить SSL-сертификат (например, от Let's Encrypt) для вашего домена и настроить его в Kong для прокси-порта `:8443`. Это обеспечит работу по протоколу HTTPS.

3.  **Аутентификация запросов**:
    *   Как описано в `AUTH_IMPLEMENTATION.md`, на все маршруты, кроме публичных, должен быть применен плагин `oidc` (OpenID Connect), который будет проверять JWT-токены, выданные Keycloak. Это центральный механизм защиты ваших микросервисов.


## 6. Наблюдаемость (Observability)

Для эффективной эксплуатации в продакшене приложение должно предоставлять данные о своем состоянии.

### 6.1. Логирование

-   **Формат**: Все логи выводятся в `stdout` в виде **структурированного JSON**. Это стандарт для контейнеризированных приложений, позволяющий системам сбора логов (например, Fluentd, Logstash, Google Cloud Logging) легко их парсить и индексировать.
-   **Уровни**: Детализация логов настраивается через переменную окружения `LOG_LEVEL`. Возможные значения: `error`, `warn`, `log`, `debug`, `verbose`.
    -   Для `development`: рекомендуется `debug` или `verbose`.
    -   Для `production`: рекомендуется `log` или `warn`.
-   **Реализация**: Настроен кастомный `JsonLogger`, который реализует интерфейс `LoggerService` из NestJS.

### 6.2. Трассировка и Метрики (План)

-   **Трассировка**: Для отслеживания запросов между микросервисами необходимо внедрить **OpenTelemetry**. Это позволит строить "карту" прохождения запроса через всю систему и быстро находить узкие места.
-   **Метрики**: Для сбора метрик (время ответа, количество ошибок, использование памяти) планируется использовать **Prometheus**. NestJS имеет готовые модули для интеграции с Prometheus.

## 7. Взаимодействие с AI-сервисами (Genkit)

Для обеспечения безопасности и контроля, Genkit-флоу не должны вызываться напрямую с фронтенда в продакшене.

1.  **Backend-for-Frontend (BFF)**: Создайте специальный сервис или эндпоинты в существующих сервисах, которые будут выступать в роли прокси для Genkit.
2.  **Аутентификация**: Эти прокси-эндпоинты должны быть защищены JWT, как и остальные части API.
3.  **Передача данных**: BFF-эндпоинт принимает запрос от фронтенда, обогащает его необходимой информацией из базы данных (например, полная статистика игрока) и затем вызывает соответствующий Genkit-флоу.
4.  **Безопасность ключей**: `GOOGLE_API_KEY` должен храниться только на бэкенде и никогда не передаваться на клиент.
