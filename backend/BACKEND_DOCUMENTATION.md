# Техническая Документация Бэкенда "ProDvor"

Этот документ служит центральным источником информации для разработки, развертывания и поддержки серверной части платформы "ProDvor".

## 1. Обзор архитектуры

Мы используем микросервисную архитектуру для обеспечения гибкости, масштабируемости и независимого развертывания компонентов.

-   **API Gateway (Kong)**: Единая точка входа для всех клиентских запросов. Отвечает за маршрутизацию, аутентификацию (проверка JWT), ограничение скорости и логирование.
-   **Identity Provider (Keycloak)**: Централизованное управление пользователями, ролями, аутентификацией и авторизацией. Для надежности в продакшене использует **выделенную PostgreSQL базу данных**.
-   **Основные сервисы (Node.js)**: Набор микросервисов, отвечающих за конкретную бизнес-логику:
    -   **`user-service`**: Управление профилями пользователей, настройками, друзьями.
    -   **`team-service`**: Создание команд, управление составом, заявки на вступление.
    -   **`tournament-service`**: Управление турнирами, генерация сеток, обработка результатов.
    -   **`match-service`**: Логика матчей, статистика, разрешение споров.
    -   **`chat-service`**: Обработка real-time сообщений через WebSocket, управление комнатами чатов, история сообщений. Для обеспечения надежной доставки и масштабируемости использует брокер сообщений.
    -   **`notification-service`**: Отправка асинхронных уведомлений (push, email).
-   **Брокер сообщений (Kafka & RabbitMQ)**: Асинхронное взаимодействие между сервисами. Используется для доставки сообщений в `chat-service`, обработки оффлайн-сообщений и для `notification-service`.
-   **База данных (PostgreSQL)**: Основное хранилище данных для всех сервисов.
-   **AI Gateway (Genkit)**: Отдельный шлюз или сервис, который инкапсулирует взаимодействие с моделями Google AI, предоставляя безопасные эндпоинты для фронтенда.

## 2. Технологический стек

| Компонент            | Технология                    | Примечание                                                          |
| :---                 | :---                          | :---                                                                |
| **Среда выполнения** | Node.js (v20+)                | Используем LTS-версию для стабильности.                             |
| **Фреймворк**        | NestJS                        | Предоставляет модульную архитектуру и DI "из коробки".              |
| **База данных**      | PostgreSQL (v15+)             | Надежная и масштабируемая реляционная СУБД.                         |
| **ORM**              | Prisma                        | Упрощает взаимодействие с базой данных и миграции.                  |
| **API Gateway**      | Kong                          | Централизованная обработка входящих запросов.                       |
| **GUI для Kong**     | Konga                         | Веб-интерфейс для удобной настройки Kong.                           |
| **IdP**              | Keycloak                      | Управление пользователями, ролями и аутентификацией.                |
| **Брокер сообщений** | Apache Kafka & RabbitMQ       | Для асинхронных операций, стриминга и сверхвысоких нагрузок.         |
| **Контейнеризация**  | Docker, Docker Compose        | Для локальной разработки и развертывания.                           |
| **Кеширование**      | Redis                         | Для кеширования сессий, часто запрашиваемых данных.                 |

### Модель "Правильный инструмент для правильной задачи": Kafka + RabbitMQ

В сложных микросервисных системах абсолютно нормально и даже часто правильно использовать несколько брокеров сообщений, выбирая лучший инструмент для каждой конкретной задачи. Наш выбор — это комбинация Kafka и RabbitMQ.

| Задача                                     | Рекомендуемый брокер | Почему?                                                                                                       |
| :----------------------------------------- | :------------------- | :------------------------------------------------------------------------------------------------------------ |
| **Сообщения в чате в реальном времени**                       | **Kafka**            | Нужна высокая пропускная способность, гарантированный порядок и возможность хранить историю для новых участников. |
| **Уведомления (push, email), фоновые задачи** | **RabbitMQ**         | Идеально для **очередей задач (task queues)**. Можно легко маршрутизировать задания разным "воркерам" (email-sender, push-sender, report-generator). |
| **Статистика матчей в реальном времени**   | **Kafka**            | Это классический поток событий (event stream), который можно будет анализировать в реальном времени.         |
| **Видео-трансляции (будущая фича)**        | **Kafka**            | Это основная причина выбора Kafka. Он создан для обработки потоков данных такого масштаба.                    |
| **Отложенные задачи (генерация отчета и т.д.)** | **RabbitMQ**         | Отличный выбор для отложенных задач, которые не требуют строгой последовательности событий.                   |

**Архитектурное решение для ProDvor:** Для обеспечения максимальной эффективности и использования правильного инструмента для каждой задачи, наша архитектура **с самого начала включает и Kafka, и RabbitMQ**.

-   **Kafka** служит основой для высоконагруженных потоков данных: чаты, статистика в реальном времени, и будущие видео-трансляции.
-   **RabbitMQ** используется как классический **брокер и очередь задач (task queue)** для асинхронных операций, таких как отправка уведомлений, обработка фоновых заданий (например, генерация PDF-отчета) и других сценариев, где важна гибкая маршрутизация.

Такой подход "polyglot messaging" позволяет нам строить более надежную и специализированную систему, готовую к любым нагрузкам, не вводя в стек дополнительные технологии вроде BullMQ, когда их роль уже успешно выполняет RabbitMQ.

### RabbitMQ как Task Queue (Альтернатива BullMQ)

Иногда возникает вопрос: "Почему бы не использовать BullMQ для фоновых задач, ведь он так удобен?". Это справедливый вопрос, и вот наш ответ:

| Возможность BullMQ           | Как это решает RabbitMQ + NestJS (`@golevelup/nestjs-rabbitmq`)                                     | Выгода нашего подхода                                                                                             |
|:-----------------------------|:---------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------------------------|
| **Простое управление очередями** | Декоратор `@RabbitSubscribe` автоматически создает очереди, обменники и привязки (bindings).        | Нет необходимости в ручной настройке. Код остается чистым и декларативным.                                        |
| **Отказоустойчивость воркеров**  | Механизм подтверждений (ACK/NACK) встроен в протокол AMQP. Если воркер падает, задача возвращается в очередь. | Гарантия доставки "из коробки" на уровне протокола, а не библиотеки. Промышленный стандарт надежности.            |
| **Отложенные задачи**         | Стандартный паттерн "Dead Letter Exchange + Message TTL".                                          | Мощный и гибкий механизм, который не привязан к конкретной реализации и широко используется в индустрии.        |
| **Управление конкурентностью**   | Настройка `prefetchCount` (QoS) на уровне канала.                                                | Позволяет тонко контролировать, сколько задач может одновременно обрабатывать каждый воркер.                     |
| **Веб-интерфейс**            | Встроенный плагин `rabbitmq_management`. Уже доступен в нашем Docker Compose на порту `15672`.       | Полноценный, официальный UI для мониторинга и управления всем брокером, а не только очередями.                    |

**Итог:** Используя RabbitMQ, мы получаем все необходимые нам возможности, не добавляя в стек еще одну технологию. Это сохраняет архитектуру более простой и предсказуемой.

## 3. Настройка окружения

Инструкции по настройке и запуску всего стека находятся в корневом `README.md` и `docker-compose.yml`.

## 4. Спецификация API (Пример для `user-service`)

Все API должны следовать спецификации OpenAPI 3.0. Документация автоматически генерируется с помощью Swagger и доступна по эндпоинту `/api-docs` на запущенном бэкенд-сервисе.

## 5. Аутентификация и авторизация (детально)

Процесс описан в [AUTH_IMPLEMENTATION.md](AUTH_IMPLEMENTATION.md).

Ключевые моменты для бэкенда:
1.  **Защита API**: Все эндпоинты, кроме публичных (`/register`, `/login`, `/health`), должны быть защищены в Kong с помощью `openid-connect` плагина.
2.  **Информация о пользователе**: Kong, после валидации JWT, передает информацию о пользователе (claims) в заголовках (`X-Userinfo`, `X-Authenticated-Userid`). Сервисы должны доверять этим заголовкам.
3.  **Регистрация**: Эндпоинт `/register` должен быть публичным. Он принимает данные пользователя, валидирует их и использует **Keycloak Admin API** для создания нового пользователя. Для этого необходим сервисный аккаунт с правами `manage-users`.
4.  **Роли**: Сервисы должны проверять роль пользователя (переданную в JWT) для выполнения авторизованных действий.

## 6. Взаимодействие с AI-сервисами (Genkit)

Для обеспечения безопасности и контроля, Genkit-флоу не должны вызываться напрямую с фронтенда в продакшене.

1.  **Backend-for-Frontend (BFF)**: Создайте специальный сервис или эндпоинты в существующих сервисах, которые будут выступать в роли прокси для Genkit.
2.  **Аутентификация**: Эти прокси-эндпоинты должны быть защищены JWT, как и остальные части API.
3.  **Передача данных**: BFF-эндпоинт принимает запрос от фронтенда, обогащает его необходимой информацией из базы данных (например, полная статистика игрока) и затем вызывает соответствующий Genkit-флоу.
4.  **Безопасность ключей**: `GOOGLE_API_KEY` должен храниться только на бэкенде и никогда не передаваться на клиент.

## 7. Хранение и доставка статичных файлов (Object Storage + CDN)

### 7.1. Проблема

Хранение статичных файлов (аватары, баннеры, видео) непосредственно на диске бэкенд-сервера является **анти-паттерном** в микросервисной архитектуре. Это приводит к следующим проблемам:
-   **Масштабируемость:** Файл, загруженный на один экземпляр сервиса, будет недоступен для других.
-   **Недолговечность:** При перезапуске Docker-контейнера все локально сохраненные файлы будут потеряны.
-   **Производительность:** Бэкенд-сервис будет тратить ресурсы на отдачу файлов, что не является его основной задачей.

### 7.2. Архитектурное решение

Для решения этой задачи мы используем стандартный для индустрии двухкомпонентный подход: **Object Storage** для хранения и **CDN** для доставки.

1.  **Хранилище (Object Storage):**
    -   **Технология:** Любой S3-совместимый сервис (например, Google Cloud Storage, Amazon S3, MinIO для локальной разработки).
    -   **Роль:** Централизованное, надежное и масштабируемое хранилище для всех статичных файлов.

2.  **Доставка (Content Delivery Network):**
    -   **Технология:** Cloudflare, Google Cloud CDN, Amazon CloudFront и т.д.
    -   **Роль:** Кэширование файлов на серверах по всему миру (edge locations) для сверхбыстрой доставки контента пользователям и снижения нагрузки на Object Storage.

### 7.3. Флоу работы с файлами

**Загрузка файла (например, аватара):**
1.  Клиент (фронтенд) отправляет файл на специальный эндпоинт бэкенда.
2.  Бэкенд **не сохраняет файл на диск**. Он выступает в роли прокси и загружает полученный файл напрямую в бакет Object Storage.
3.  После успешной загрузки Object Storage возвращает уникальный URL файла.
4.  Бэкенд сохраняет этот **URL** в соответствующее поле в базе данных PostgreSQL (например, `avatar` в таблице `User`).

**Отображение файла:**
1.  Клиент запрашивает у API данные о пользователе.
2.  Бэкенд возвращает JSON, где в поле `avatar` находится URL файла из Object Storage.
3.  Браузер клиента делает GET-запрос по этому URL.
4.  Запрос перехватывается **CDN**. Если у CDN есть кэш файла на ближайшем к пользователю сервере, он отдает его мгновенно. Если нет — запрашивает его из Object Storage, кэширует у себя и отдает пользователю.
