# Техническая Документация Бэкенда "ProDvor"

Этот документ служит центральным источником информации для разработки, развертывания и поддержки серверной части платформы "ProDvor".

## 1. Обзор архитектуры

Мы используем микросервисную архитектуру для обеспечения гибкости, масштабируемости и независимого развертывания компонентов.

-   **API Gateway (Kong)**: Единая точка входа для всех клиентских запросов. Отвечает за маршрутизацию, аутентификацию (проверка JWT), ограничение скорости и логирование.
-   **Identity Provider (Keycloak)**: Централизованное управление пользователями, ролями, аутентификацией и авторизацией.
-   **Основные сервисы (Node.js)**: Набор микросервисов, отвечающих за конкретную бизнес-логику:
    -   **`user-service`**: Управление профилями пользователей, настройками, друзьями.
    -   **`team-service`**: Создание команд, управление составом, заявки на вступление.
    -   **`tournament-service`**: Управление турнирами, генерация сеток, обработка результатов.
    -   **`match-service`**: Логика матчей, статистика, разрешение споров.
    -   **`chat-service`**: Обработка real-time сообщений через WebSocket, управление комнатами чатов, история сообщений. Для обеспечения надежной доставки и масштабируемости использует брокер сообщений.
    -   **`notification-service`**: Отправка асинхронных уведомлений (push, email).
-   **Брокер сообщений (Kafka)**: Асинхронное взаимодействие между сервисами. Используется для доставки сообщений в `chat-service`, обработки оффлайн-сообщений и для `notification-service`.
-   **База данных (PostgreSQL)**: Основное хранилище данных для всех сервисов.
-   **AI Gateway (Genkit)**: Отдельный шлюз или сервис, который инкапсулирует взаимодействие с моделями Google AI, предоставляя безопасные эндпоинты для фронтенда.

## 2. Технологический стек

| Компонент            | Технология                    | Примечание                                                          |
| :---                 | :---                          | :---                                                                |
| **Среда выполнения** | Node.js (v20+)                | Используем LTS-версию для стабильности.                             |
| **Фреймворк**        | NestJS                        | Предоставляет модульную архитектуру и DI "из коробки".              |
| **База данных**      | PostgreSQL (v15+)             | Надежная и масштабируемая реляционная СУБД.                         |
| **ORM**              | Prisma                        | Упрощает взаимодействие с базой данных и миграции.                  |
| **API Gateway**      | Kong                          | Централизованная обработка входящих запросов.                       |
| **GUI для Kong**     | Konga                         | Веб-интерфейс для удобной настройки Kong.                           |
| **IdP**              | Keycloak                      | Управление пользователями, ролями и аутентификацией.                |
| **Брокер сообщений** | Apache Kafka                  | Для асинхронных операций, стриминга и сверхвысоких нагрузок.         |
| **Контейнеризация**  | Docker, Docker Compose        | Для локальной разработки и развертывания.                           |
| **Кеширование**      | Redis                         | Для кеширования сессий, часто запрашиваемых данных.                 |

### Выбор брокера: Kafka как основа для масштабирования

С учетом долгосрочных целей — поддержка **трансляций, стримов и аудитории в 80 миллионов пользователей** — выбор однозначно падает на **Apache Kafka**.

Изначально для прототипа мог бы подойти более легковесный брокер вроде NATS или RabbitMQ, но для заявленных масштабов они не обладают необходимой пропускной способностью и возможностями обработки потоков.

**Почему Kafka — это правильный выбор для ProDvor:**

| Критерий                     | Kafka                                                                                       | Другие брокеры (NATS/RabbitMQ)                                             | Обоснование для ProDvor                                                                                                               |
| :---                         | :---                                                                                        | :---                                                                       | :---                                                                                                                                  |
| **Масштабируемость и Throughput** | Спроектирован для **триллионов сообщений в день**. Горизонтально масштабируется до огромных кластеров. | Оптимизированы для low-latency, но уступают в чистой пропускной способности. | **80 млн пользователей** будут генерировать колоссальный объем событий (чаты, действия, статистика). Kafka справится с этой нагрузкой.     |
| **Обработка потоков (Streaming)** | Нативная поддержка стриминга и обработки потоков данных (Kafka Streams, ksqlDB).          | В основном используются для простой доставки сообщений (point-to-point, pub/sub). | Это **ключевое требование** для будущих трансляций и стримов. Мы сможем в реальном времени обрабатывать видеопотоки, статистику и т.д. |
| **Надежность и персистентность**  | Данные хранятся в **распределенном, отказоустойчивом логе**. Возможен повторный просмотр событий. | Персистентность есть, но не является ядром архитектуры, как у Kafka.      | Мы не можем позволить себе терять сообщения чатов или события матчей. Прочный лог Kafka гарантирует сохранность данных.             |
| **Экосистема и комьюнити**      | Огромная экосистема коннекторов (базы данных, хранилища) и мощное комьюнити. Промышленный стандарт. | Экосистемы меньше и более нишевые.                                          | Мы сможем легко интегрировать аналитические системы, data lake и другие сервисы в будущем.                                           |

**Вывод:** Несмотря на более высокий порог входа, **Kafka является стратегически верным выбором**. Он закладывает фундамент для платформы, способной выдержать сверхвысокие нагрузки и реализовать сложный функционал, такой как real-time стриминг и аналитика.

## 3. Настройка окружения

### Пример `docker-compose.yml`

*Заглушка: Здесь будет полная конфигурация docker-compose.yml для всех сервисов, включая PostgreSQL, Keycloak, Kong, NATS и сервисы приложения.*

## 4. Спецификация API (Пример для `user-service`)

Все API должны следовать спецификации OpenAPI 3.0.

*Заглушка: Здесь будет детальный пример спецификации OpenAPI 3.0 для user-service.*

## 5. Аутентификация и авторизация (детально)

Процесс описан в [AUTH_IMPLEMENTATION.md](AUTH_IMPLEMENTATION.md).

Ключевые моменты для бэкенда:
1.  **Защита API**: Все эндпоинты, кроме публичных (`/register`, `/login`, `/health`), должны быть защищены в Kong с помощью `openid-connect` плагина.
2.  **Информация о пользователе**: Kong, после валидации JWT, передает информацию о пользователе (claims) в заголовках (`X-Userinfo`, `X-Authenticated-Userid`). Сервисы должны доверять этим заголовкам.
3.  **Регистрация**: Эндпоинт `/register` должен быть публичным. Он принимает данные пользователя, валидирует их и использует **Keycloak Admin API** для создания нового пользователя. Для этого необходим сервисный аккаунт с правами `manage-users`.
4.  **Роли**: Сервисы должны проверять роль пользователя (переданную в JWT) для выполнения авторизованных действий.

## 6. Взаимодействие с AI-сервисами (Genkit)

Для обеспечения безопасности и контроля, Genkit-флоу не должны вызываться напрямую с фронтенда в продакшене.

1.  **Backend-for-Frontend (BFF)**: Создайте специальный сервис или эндпоинты в существующих сервисах, которые будут выступать в роли прокси для Genkit.
2.  **Аутентификация**: Эти прокси-эндпоинты должны быть защищены JWT, как и остальные части API.
3.  **Передача данных**: BFF-эндпоинт принимает запрос от фронтенда, обогащает его необходимой информацией из базы данных (например, полная статистика игрока) и затем вызывает соответствующий Genkit-флоу.
4.  **Безопасность ключей**: `GOOGLE_API_KEY` должен храниться только на бэкенде и никогда не передаваться на клиент.
